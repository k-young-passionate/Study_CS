# 리소스 관리와 오토 스케일링

## 리소스 제한

- container 단위로 리소스 제한 가능

### CPU/Memory

- CPU: 1vCPU (가상 CPU)를 1,000m 단위로 지정
  - 1 = 1000m = 1 vCPU
- Memory: 실제 memory 단위로 지정
  - 1G = 1000M / 1Gi = 1024Mi

```yaml
apiVersion: apps/v1
kind: Deployment
...
sepc:
  ...
  spec:
    containers:
    - name: nginx-container
      ...
      resources:
        requests:
          memory: "1024Mi"
          cpu: "500m"
        limits:
          memory: "2048Mi"
          cpu: "1000m"
```

#### 구성

- requests: 최솟값
  - 설정하지 않으면 `limits`와 같은 값 배정
- limits: 최댓값
  - 설정하지 않으면 제한 없이 사용
- requests < limits 이지만 차이가 너무 큰 container에서 부하 상승시 실제로 사용하려는 리소스 양과 차이 발생

#### 사용량 확인

```bash
$ kubectl describe node
```

### Ephemeral storage resource 제어

- storage
  - 일반적: PV를 사용하여 그곳의 data를 씀
  - 재기동시 삭제되어도 좋은 데이터: container 내부의 disk영역을 사용 가능
- log data 대량 출력 => disk 영역 많이 차지
  - disk 영역 제한: Ephemeral storage resource 제한
- Ephemeral storage 용량으로 계산되는 것들
  - container가 출력하는 로그
  - emptyDir에 기록된 data(메모리가 아닌 것)
  - container의 쓰기 가능한 layer에 기록된 데이터

```yaml
...
spec:
  ...
    resources:
      requests:
        ephemeral-storage: "1024Mi"
      limits:
        ephemeral-storage: "2048Mi"
```


### 시스템에 할당된 리소스와 Eviction Manager

- CPU, Memory, Ephemeral Storage의 일반적 resource는 완전히 고갈 시 k8s가 동작하지 않거나 node 전체에 영향
- 이러한 사태 방지를 위해 `kube-reserved`, `system-reserved` resource가 system용으로 확보
- `Allocatable` resource는 resource 총량에서 `kube-reserved`, `system-reserved`를 제외한 양

#### 종류

- `kube-reserved`: k8s 시스템 구성 요소나 container runtime에 확보된 resource
- `system-reserved`: OS에 깊이 관련된 daemon 등에 확보된 resource

#### Eviction Manager

- system 전체가 과부화되지 않도록 관리
- `Allocatable`, `system-reserved`, `kube-reserved`에서 실제로 사용되는 resource 합계가 eviction threshold 초과하지 않는지 정기적으로 확인
  - 초과될 경우 pod evict
- eviction threshold 종류
  - soft: SIGTERM 신호 => 정지까지 시간 걸림
  - hard: SIGKILL 신호
- evict 우선순위
  - Requests에 할당된 양보다 초과하여 resource 소비하고 있는 것
  - PodPriority가 더 낮은 것
  - Requests에 할당된 양보다 초과하여 소비하고 있는 resource 양이 더 많은 것

### GPU 등의 리소스 제한

```yaml
resource:
  requests:
    nvidia.com/gpu: 2
  limits:
    nvidia.com/gpu: 2
```

### Overcommit과 resource 부족

- overcommit: 할당 안했는데 할당한 것처럼 반환

### 여러 컨테이너 사용 시 리소스 할당

- 필요한 resource 양: MAX(SUM(`모든 container resource`), MAX(`모든 init container resource`))

## Cluster Autoscaler와 리소스 부족

- resource에 의한 scheduling은 Requests를 기준으로 이루어짐
  - Requests를 초과하여 할당한 경우 최신 resource 요청만으로 resource가 꽉 차 버려서 신규 노드를 추가해야 함
- requests를 크게 설정한 경우: 실 사용량이 적어 scale-out 되지 않음
- limit와 requests 차이를 크게 설정한 경우: resource 사용량이 높아져도 scale-out 되지 않음

## LimitRange를 사용한 resource 제한

- LimitRange
  - resource의 최소/최댓값, 기본값 등을 설정 가능
  - Namespace마다 설정 필요
  - 기존 pod에는 영향 X
  - Pod/Container/PVC 에서만 설정 가능


설정 항목 | 개요 | 사용 가능한 type
-- | -- | --
default | 기본 Limits | Container
defaultRequest | 기본 Requests | Container
max | 최대 resource | Container, Pod, PVC
min | 최소 resource | Container, Pod, PVC
maxLimitRequestRatio | Limits/Requests의 비율 | Container, Pod

### 기본으로 생성되는 LimitRange

- Requests 에서 지정한 Resource를 확보할 수 있을지에 따라 scheduling 여부 판단
- 모든 Pod에 Requests를 지정하지 않았을 경우 Scheduler는 계속 해당 node에 scheduling
- 과도한 scheduling으로 resource 소비 과도한 증가 => 운영체제 멈춤
  - CPU Requests를 설정하는 LimitRange 생성되어 있음

### Container에 대한 LimitRange

- `type: Container`의 LimitRange로 설정

```yaml
apiVersion: v1
kind: LimitRange
metadata:
  name: sample-limitrange-container
  namespace: default
spec:
  limits:
  - type: Container
    default:
      memory: 512Mi
      cpu: 500m
    defaultRequest:
      memory: 256Mi
      cpu: 250m
    max:
      memory: 1024Mi
      cpu: 1000m
    min:
      memory: 128Mi
      cpu: 125m
    maxLimitRequestRatio:
      memory: 2
      cpu: 2
```

### Pod에 대한 LimitRange

- `type: Pod`의 LimitRange로 설정

```yaml
...
spec:
  limits:
  - type: Pod
    ...
```

### PVC에 대한 LmitRange

- `type: PersistentVolumeClaim`의 LimitRange로 설정

```yaml
...
spec:
  limits:
  - type: PersistentVolumeClaim
    ...
```
